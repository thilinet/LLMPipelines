{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f356c43-bc3b-4058-af0c-c77a3ee16cfc",
   "metadata": {},
   "source": [
    "## Load sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce606f6-b269-4009-9787-feb7a1a12c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset to /teamspace/studios/this_studio/.adalflow/cache_datasets/object_counting/object_counting.json\n",
      "Saving train split to /teamspace/studios/this_studio/.adalflow/cache_datasets/object_counting/train.csv\n",
      "Saving val split to /teamspace/studios/this_studio/.adalflow/cache_datasets/object_counting/val.csv\n",
      "Saving test split to /teamspace/studios/this_studio/.adalflow/cache_datasets/object_counting/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-10-17 19:55:20--  https://raw.githubusercontent.com/suzgunmirac/BIG-Bench-Hard/main/bbh/object_counting.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35890 (35K) [text/plain]\n",
      "Saving to: ‘/teamspace/studios/this_studio/.adalflow/cache_datasets/object_counting/object_counting.json’\n",
      "\n",
      "     0K .......... .......... .......... .....                100% 59.8M=0.001s\n",
      "\n",
      "2024-10-17 19:55:20 (59.8 MB/s) - ‘/teamspace/studios/this_studio/.adalflow/cache_datasets/object_counting/object_counting.json’ saved [35890/35890]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from adalflow.datasets.big_bench_hard import BigBenchHard\n",
    "from adalflow.utils.data import subset_dataset\n",
    "\n",
    "def load_datasets(max_samples: int = None):\n",
    "    \"\"\"Load the dataset\"\"\"\n",
    "    train_data = BigBenchHard(split=\"train\")\n",
    "    val_data = BigBenchHard(split=\"val\")\n",
    "    test_data = BigBenchHard(split=\"test\")\n",
    "\n",
    "    # Limit the number of samples\n",
    "    if max_samples:\n",
    "        train_data = subset_dataset(train_data, max_samples)\n",
    "        val_data = subset_dataset(val_data, max_samples)\n",
    "        test_data = subset_dataset(test_data, max_samples)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "train, test, val = load_datasets(max_samples = 5)\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for example_instance in train:\n",
    "    questions.append(example_instance.question)\n",
    "    answers.append(example_instance.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a1d7b3-a6e2-412f-a34e-a2ce2ce7292b",
   "metadata": {},
   "source": [
    "### Test use case with a simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dafe82-caf2-4b4d-aeb2-f31c93032927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have an apple, three bananas, a strawberry, a peach, three oranges, a plum, a raspberry, two grapes, a nectarine, and a blackberry. How many fruits do I have?\n",
      "predicted 10 actual 15\n",
      "*************************\n",
      "I have a banana, four strawberries, an apple, two peaches, a plum, a blackberry, and two raspberries. How many fruits do I have?\n",
      "predicted 10 actual 12\n",
      "*************************\n",
      "I have three yams, a lettuce head, an onion, a potato, a cabbage, a carrot, two heads of broccoli, and two stalks of celery. How many vegetables do I have?\n",
      "predicted 12 actual 12\n",
      "*************************\n",
      "I have a chicken, a frog, a mouse, a cat, two pigs, and two rabbits. How many animals do I have?\n",
      "predicted 5 actual 8\n",
      "*************************\n",
      "I have a trombone, a violin, a clarinet, an accordion, four flutes, a trumpet, two drums, and a piano. How many musical instruments do I have?\n",
      "predicted 10 actual 12\n",
      "*************************\n",
      "Accuracy 20.0%\n"
     ]
    }
   ],
   "source": [
    "from adalflow.components.model_client.ollama_client import OllamaClient\n",
    "import adalflow as adal\n",
    "import re\n",
    "\n",
    "host = \"127.0.0.1:11434\"\n",
    "\n",
    "phi3_model = {\n",
    "        \"model_client\" : OllamaClient(host=host)\n",
    "       ,\"model_kwargs\" : {\"model\":\"phi3:latest\"}\n",
    "}\n",
    "\n",
    "simple_prompt = r\"\"\"\n",
    "<SYS>You are good at recognizing objects and counting.\n",
    "Count the number of objects and respond with a numerical answer only.\n",
    "</SYS>\n",
    "User question: {{user_query}}\n",
    "You:\n",
    "\"\"\"\n",
    "counter_llm = adal.Generator(**phi3_model,template=simple_prompt)\n",
    "\n",
    "def generate_answer(user_query):\n",
    "    query = {\"user_query\": user_query}\n",
    "    output = counter_llm(query)\n",
    "    return_count = re.findall(r'\\b\\d+\\b', output.data)[0]\n",
    "    return return_count\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for idx, query in enumerate(questions):\n",
    "    print(query)\n",
    "    answer = generate_answer(query)\n",
    "    print(f\"predicted {answer} actual {answers[idx]}\")\n",
    "    print(\"*\" * 25)\n",
    "    total+=1\n",
    "    if eval(answer) == eval(answers[idx]):\n",
    "        correct+=1\n",
    "    \n",
    "print(f\"Accuracy {round(correct/total * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25719d-63e7-423d-ae2a-9db2d9f26468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
